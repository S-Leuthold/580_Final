[["index.html", "ESS580 Final Project Chapter 1 Preface", " ESS580 Final Project Sam Leuthold 2022-03-20 Chapter 1 Preface This document provides an overview of the primary assignments completed in the Spring 2022 session of the Environmental Data Science Class (SOCR580A7) at Colorado State University. Each chapter represents an individual assignment. "],["chapter-1---hayman-fire-recovery.html", "Chapter 2 Chapter 1 - Hayman Fire Recovery 2.1 Importing the data and cleaning it up. 2.2 Question 1 2.3 Question 2 2.4 Question 3 2.5 Question 4 2.6 Question 5", " Chapter 2 Chapter 1 - Hayman Fire Recovery 2.1 Importing the data and cleaning it up. files &lt;- list.files(&#39;./Data/Chapter_1/&#39;, full.names = T) ndmi &lt;- read_csv(files[1]) %&gt;% rename(Burned = 2,Unburned = 3) %&gt;% mutate(data = &quot;ndmi&quot;) ndsi &lt;- read_csv(files[2]) %&gt;% rename(Burned = 2, Unburned = 3) %&gt;% mutate(data = &quot;ndsi&quot;) ndvi &lt;- read_csv(files[3]) %&gt;% rename(Burned = 2, Unburned = 3) %&gt;% mutate(data = &quot;ndvi&quot;) ## Gather data together into a tidy tibble. full_long &lt;- rbind(ndvi, ndmi, ndsi) %&gt;% gather(key = &quot;site&quot;, value = &quot;value&quot;, -DateTime, -data) %&gt;% filter(!is.na(value)) 2.2 Question 1 What is the correlation between NDVI and NDMI? ## Create tibble with individual columns, filter summer months. Q1.data &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(month = month(DateTime, label = T)) %&gt;% filter(month %in% c(&quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;)) ## Create another tibble with all the data named &quot;all&quot;. Q1.all &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(month = month(DateTime, label = T)) %&gt;% filter(month %in% c(&quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;)) %&gt;% mutate(site = recode(site, unburned = &quot;Unburned&quot;, burned = &quot;Burned&quot;)) %&gt;% mutate(month = &quot;All&quot;) ## Combine datasets Q1.data &lt;- rbind(Q1.data, Q1.all) ### ## Create an empty tibble to fill with correlations between NDVI and NDMI for each month, and each site type. Q1.corr &lt;- tibble(month = rep(unique(Q1.data$month), 2), site = rep(unique(Q1.data$site), each = 5), Corr = vector(mode = &quot;numeric&quot;, length = 10)) ## Loop through and filter out subsets of data to run cor() on. for(i in 1:10){ temp &lt;- Q1.data %&gt;% filter(month == Q1.corr$month[i] &amp; site == Q1.corr$site[i]) Q1.corr$Corr[i] &lt;- paste(&quot;r = &quot;, round(cor(temp$ndmi, temp$ndvi, &quot;complete.obs&quot;),2)) } ### ## Plot data. ggplot(data = Q1.data, aes(x = ndmi, y = ndvi)) + geom_point(fill = &quot;lightgrey&quot;, shape = 21, size = 3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, lty = 1, color = &quot;black&quot;, size = 1.5) + facet_grid(month~site) + scale_x_continuous(name = &quot;NDMI&quot;, limits = c(-0.4, 0.4)) + scale_y_continuous(name = &quot;NDVI&quot;, limits = c(0, 0.75)) + geom_text(data = Q1.corr, aes(x = 0.3, y = 0.65, label = Corr, fill = NULL, group = month)) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), strip.background = element_blank(), axis.text = element_text(color = &quot;black&quot;)) There is a strong correlation between NDVI and NDMI in summer months in areas that have been burnt. Overall, the correlation coefficient (r) is 0.71 (Figure 1), with the strongest relationship occuring in July and August (r = 0.84 and 0.85, respectivley), and the weakest occuring in September (r = 0.54). The correlation is not as strong in the unburned area; the correlation between NDMI and NDVI across summer months is 0.17, with a negative correlation coefficent manifesting in September (-0.08), though this is likely spurious. 2.3 Question 2 What is the correlation between average NDSI for January - April and average NDVI for June-August? ## Create a dataset with just the winter values, then find the annual average winter NDSI Q2.data.winter &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(Year = year(DateTime), Month = month(DateTime)) %&gt;% filter(Month %in% c(1, 2, 3, 4)) %&gt;% group_by(site, Year) %&gt;% summarise(Mean_Winter_NDSI = mean(ndsi)) ## Create a dataset with just the summer values, then find the annual average summer NDVI Q2.data.summer &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(Year = year(DateTime), Month = month(DateTime)) %&gt;% filter(Month %in% c(6, 7, 8)) %&gt;% group_by(site, Year) %&gt;% summarise(Mean_Summer_NDVI = mean(ndvi)) ## Combine the datasets Q2.data &lt;- inner_join(Q2.data.summer, Q2.data.winter) ## Find the correlation between summer NDVI and winter NDSI Q2.Corr &lt;- paste(&quot;r = &quot;, round(cor(Q2.data$Mean_Summer_NDVI, Q2.data$Mean_Winter_NDSI, use = &quot;complete.obs&quot;), 3)) ## Plot data ggplot(data = Q2.data, aes(x = Mean_Winter_NDSI, y = Mean_Summer_NDVI)) + geom_point(fill = &quot;lightgrey&quot;, shape = 21, size = 4) + geom_smooth(method = &quot;lm&quot;, se = FALSE, lty = 2, color = &quot;black&quot;, size = 1.5) + scale_x_continuous(name = &quot;Mean Winter NDSI&quot;, limits = c(-0.5, 0.6)) + scale_y_continuous(name = &quot;Mean Summer NDVI&quot;, limits = c(0.11, 0.6)) + annotate(geom = &quot;text&quot;, x = 0.5, y = 0.6, label = Q2.Corr) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), axis.text = element_text(color = &quot;black&quot;)) There is a weak correlation between mean winter NDSI and mean summer NDVI across burned and unburned areas. The correlation coefficient is 0.198, however there is significant spread in the data. 2.4 Question 3 How is the snow effect from question 2 different between pre- and post-burn and burned and unburned? ## Add column for site burn timing to Q2.data. Q3.data &lt;- Q2.data %&gt;% mutate(Status = if_else(Year &lt; 2002, &quot;Pre-Burn&quot;, &quot;Post-Burn&quot;)) ## Use the same for loop structure from Q 1 to calculate correlations for each subset of data. Q3.corr &lt;- tibble(Status = rep(unique(Q3.data$Status), 2), site = rep(unique(Q3.data$site), each = 2), Corr = vector(mode = &quot;numeric&quot;, length = 4)) ## Loop through and filter out subsets of data to run cor() on. for(i in 1:4){ temp &lt;- Q3.data %&gt;% filter(Status == Q3.corr$Status[i] &amp; site == Q3.corr$site[i]) Q3.corr$Corr[i] &lt;- paste(&quot;r = &quot;, round(cor(temp$Mean_Winter_NDSI, temp$Mean_Summer_NDVI, &quot;complete.obs&quot;),3)) } ### ## Plot data ggplot(data = Q3.data, aes(x = Mean_Winter_NDSI, y = Mean_Summer_NDVI)) + geom_point(fill = &quot;lightgrey&quot;, shape = 21, size = 4) + geom_smooth(method = &quot;lm&quot;, se = FALSE, lty = 2, color = &quot;black&quot;, size = 1.5) + facet_grid(Status~site) + scale_x_continuous(name = &quot;Mean Winter NDSI&quot;, limits = c(-0.5, 0.6)) + scale_y_continuous(name = &quot;Mean Summer NDVI&quot;, limits = c(0.11, 0.6)) + geom_text(data = Q3.corr, aes(x = 0.45, y = 0.55, label = Corr)) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), axis.text = element_text(color = &quot;black&quot;)) The mean summer NDVI is negatively related to mean winter NDSI in the burned areas after the burn, which is interesting. I would have expected that these areas would see the greatest response to increased winter moisture. However, across the board, there were not significant relationships between NDSI and NDVI, perhaps reflecting that these systems are most sensitive to summer precipitation rather than snowmelt inputs. 2.5 Question 4 What month is the greenest month on average? Q4.data &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(Year = year(DateTime), Month = month(DateTime, label = T)) %&gt;% group_by(Month) %&gt;% summarise(Mean_NDVI = mean(ndvi, na.rm = T)) Q4.data %&gt;% filter(Mean_NDVI == max(Mean_NDVI)) ## # A tibble: 1 x 2 ## Month Mean_NDVI ## &lt;ord&gt; &lt;dbl&gt; ## 1 Aug 0.387 ggplot(data = Q4.data, aes(x = Month, y = Mean_NDVI)) + geom_col(fill = &quot;lightgrey&quot;, color = &quot;black&quot;) + geom_col(data = Q4.data[Q4.data$Month == &quot;Aug&quot;,], aes(x = Month, y = Mean_NDVI), fill = &quot;forestgreen&quot;, color = &quot;black&quot;) + geom_hline(yintercept = 0) + scale_y_continuous(limits = c(0, 0.45), expand = c(0, 0)) + ylab(&quot;Mean NDVI&quot;) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), axis.text = element_text(color = &quot;black&quot;)) August is the greenest month on average. 2.6 Question 5 What month is the snowiest on average? Q5.data &lt;- full_long %&gt;% filter(!is.na(value)) %&gt;% pivot_wider(names_from = c(data), values_from = c(value)) %&gt;% mutate(Year = year(DateTime), Month = month(DateTime, label = T)) %&gt;% group_by(Month) %&gt;% summarise(Mean_NDSI = mean(ndsi, na.rm = T)) Q5.data %&gt;% filter(Mean_NDSI == max(Mean_NDSI)) ## # A tibble: 1 x 2 ## Month Mean_NDSI ## &lt;ord&gt; &lt;dbl&gt; ## 1 Jan 0.210 ggplot(data = Q5.data, aes(x = Month, y = Mean_NDSI)) + geom_col(fill = &quot;lightgrey&quot;, color = &quot;black&quot;) + geom_col(data = Q5.data[Q5.data$Month == &quot;Jan&quot;,], aes(x = Month, y = Mean_NDSI), fill = &quot;red&quot;, color = &quot;black&quot;) + geom_hline(yintercept = 0) + ylab(&quot;Mean NDSI&quot;) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), axis.text = element_text(color = &quot;black&quot;)) January is the snowiest month on average. "],["chapter-2---snow-studies-analysis.html", "Chapter 3 Chapter 2 - Snow Studies Analysis 3.1 Question 1 3.2 Question 2 3.3 Question 3 3.4 Question 4 3.5 Question 5 3.6 Question 6 3.7 Question 7 3.8 Question 8", " Chapter 3 Chapter 2 - Snow Studies Analysis 3.1 Question 1 Extract the meteorological data URLs from the Snow Studies Archive. site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; webpage &lt;- read_html(site_url) links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 3.2 Question 2 Download and save the the meteorological data to disk. labels &lt;- links %&gt;% str_split_fixed(&quot;/&quot;, n = 8) dataset &lt;- labels[,8] file.names &lt;- paste0(&#39;data/&#39;,dataset) map2(links[1:2], file.names[1:2], download.file) 3.3 Question 3 Write a custom function to read in the data and append a site column to the data. headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) Meteorological_Data_Download &lt;- function(site.name){ file.index &lt;- which(grepl(site.name, file.names) == T) file.path &lt;- file.names[file.index] output &lt;- read_fwf(file.path, col_positions = fwf_empty(file.path), show_col_types = F) colnames(output) &lt;- headers output &lt;- output[,1:14] output &lt;- output %&gt;% mutate(Site = site.name, .before = year) assign(paste0(site.name, &quot;.data2&quot;), output, envir = parent.frame()) } 3.4 Question 4 Use the map function to read in both meteorological files. Display a summary of your tibble. sites &lt;- c(&quot;SASP&quot;, &quot;SBSP&quot;) climate.data &lt;- map_dfr(.x = sites[1:2], .f = Meteorological_Data_Download) knitr::kable(summary(climate.data)) Site year month day hour minute second precip [kg m-2 s-1] sw down [W m-2] lw down [W m-2] air temp [K] windspeed [m s-1] relative humidity [%] pressure [Pa] specific humidity [g g-1] Length:138336 Min. :2003 Min. : 1.000 Min. : 1.00 Min. : 0.00 Min. :0 Min. :0 Min. :0.000e+00 Min. :-9999.000 Min. :-9999.0 Min. :242.1 Min. :-9999.000 Length:138336 Min. :63931 Min. :1.650e-07 Class :character 1st Qu.:2005 1st Qu.: 3.000 1st Qu.: 8.00 1st Qu.: 5.75 1st Qu.:0 1st Qu.:0 1st Qu.:0.000e+00 1st Qu.: -3.510 1st Qu.: 173.4 1st Qu.:265.8 1st Qu.: 0.852 Class :character 1st Qu.:63931 1st Qu.:1.908e-03 Mode :character Median :2007 Median : 6.000 Median :16.00 Median :11.50 Median :0 Median :0 Median :0.000e+00 Median : -0.344 Median : 231.4 Median :272.6 Median : 1.548 Mode :character Median :65397 Median :3.006e-03 NA Mean :2007 Mean : 6.472 Mean :15.76 Mean :11.50 Mean :0 Mean :0 Mean :3.838e-05 Mean :-1351.008 Mean :-1325.7 Mean :272.6 Mean : -790.054 NA Mean :65397 Mean :3.561e-03 NA 3rd Qu.:2009 3rd Qu.: 9.000 3rd Qu.:23.00 3rd Qu.:17.25 3rd Qu.:0 3rd Qu.:0 3rd Qu.:0.000e+00 3rd Qu.: 294.900 3rd Qu.: 272.2 3rd Qu.:279.7 3rd Qu.: 3.087 NA 3rd Qu.:66863 3rd Qu.:4.731e-03 NA Max. :2011 Max. :12.000 Max. :31.00 Max. :23.00 Max. :0 Max. :0 Max. :6.111e-03 Max. : 1341.000 Max. : 365.8 Max. :295.8 Max. : 317.300 NA Max. :66863 Max. :1.478e-02 3.5 Question 5 Make a line plot of mean temp by year by site (using the air temp [K] variable). Is there anything suspicious in the plot? Adjust your filtering if needed. mean.temp &lt;- climate.data %&gt;% filter(year != 2003) %&gt;% group_by(Site, year) %&gt;% summarise(Mean_Temp = mean(`air temp [K]`, na.rm = TRUE)) ggplot(data = mean.temp, aes(x = year, y = Mean_Temp)) + geom_line(aes(color = Site), size = 1.5) + geom_point(shape = 21, size = 4, aes(fill = Site)) + scale_fill_colorblind() + scale_color_colorblind() + scale_x_continuous(name = &quot;Year&quot;, breaks = seq(2003, 2011)) + ylab(&quot;Average Annual Air Temperature (K)&quot;) + theme_classic2() + theme(panel.border = element_rect(fill = NA), axis.text = element_text(color = &quot;black&quot;), legend.position = c(0.85,0.15)) 3.6 Question 6 Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot? Avg_Temp_Plotter &lt;- function(Year){ temp.temp.data &lt;- climate.data %&gt;% group_by(Site, year, month) %&gt;% summarise(Monthly_Mean = mean(`air temp [K]`)) %&gt;% filter(year == Year) temp.plot &lt;- ggplot(data = temp.temp.data, aes(x = month, y = Monthly_Mean)) + geom_line(aes(color = Site), size = 1.5) + geom_point(shape = 21, size = 4, aes(fill = Site)) + scale_fill_colorblind() + scale_color_colorblind() + scale_x_continuous(name = &quot;Year&quot;, breaks = seq(1,12)) + scale_y_continuous(name = &quot;Average Monthly Air Temperature (K)&quot;, limits = c(240, 300)) + ggtitle(label = Year) + theme_classic2() + theme(panel.border = element_rect(fill = NA), axis.text = element_text(color = &quot;black&quot;), legend.position = c(0.85,0.15)) print(temp.plot) } years &lt;- seq(2005, 2010) for (i in 1:length(years)){ Avg_Temp_Plotter(years[i]) } 3.7 Question 7 Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. daily.precipitation &lt;- climate.data %&gt;% mutate(Date = paste0(day,&quot;/&quot;, month, &quot;/&quot;, year)) %&gt;% mutate(Date = as.Date(Date, format = &quot;%d/%m/%Y&quot;)) %&gt;% mutate(DOY = yday(Date)) %&gt;% mutate(Precip_mm = `precip [kg m-2 s-1]` * 86400) %&gt;% group_by(Site, DOY) %&gt;% summarize(Mean_Precip = mean(Precip_mm)) ggplot(daily.precipitation[daily.precipitation$Site == &quot;SASP&quot;,], aes(x = DOY, y = Mean_Precip)) + geom_col(color = &quot;black&quot;, fill = &quot;lightblue&quot;) + scale_x_continuous(name = &quot;Julian Day&quot;, limits = c(-2, 367), breaks = seq(0, 360, 30), expand = c(0,0)) + scale_y_continuous(name = &quot;Mean Daily Precip (mm)&quot;, limits = c(0, 15), expand = c(0,0)) + theme_classic2() + theme(panel.border = element_rect(fill = NA), axis.text = element_text(color = &quot;black&quot;), legend.position = c(0.85,0.15)) 3.8 Question 8 Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. Yearly_Precip &lt;- function(input.year){ precip.out &lt;- climate.data %&gt;% filter(year == input.year) %&gt;% filter(Site == &quot;SASP&quot;) %&gt;% mutate(Date = paste0(day,&quot;/&quot;, month, &quot;/&quot;, year)) %&gt;% mutate(Date = as.Date(Date, format = &quot;%d/%m/%Y&quot;)) %&gt;% mutate(DOY = yday(Date)) %&gt;% mutate(Precip_mm = `precip [kg m-2 s-1]` * 86400) %&gt;% group_by(DOY) %&gt;% summarize(Mean_Precip = mean(Precip_mm)) } for(i in 1:length(unique(climate.data$year))){ annual.precip &lt;- Yearly_Precip(unique(climate.data$year)[i]) plot &lt;- ggplot(data = annual.precip, aes(x = DOY, y = Mean_Precip)) + geom_col(color = &quot;black&quot;, fill = &quot;lightblue&quot;) + scale_x_continuous(name = &quot;Julian Day&quot;, limits = c(-2, 367), breaks = seq(0, 360, 30), expand = c(0,0)) + scale_y_continuous(name = &quot;Mean Daily Precip (mm)&quot;, limits = c(0, 50), expand = c(0,0)) + ggtitle(label = unique(climate.data$year)[i]) + theme_classic2() + theme(panel.border = element_rect(fill = NA), axis.text = element_text(color = &quot;black&quot;), legend.position = c(0.85,0.15)) print(plot) } "],["chapter-3---spatial-analyses.html", "Chapter 4 Chapter 3 - Spatial Analyses 4.1 Importing the data and cleaning it up. 4.2 Question 1 4.3 Question 2 4.4 Question 3 4.5 Question 4 4.6 Question 5 4.7 Question 6 4.8 Question 7", " Chapter 4 Chapter 3 - Spatial Analyses 4.1 Importing the data and cleaning it up. lagos &lt;- lagosne_load() lake_centers &lt;- lagos$locus spatial_lakes &lt;- st_as_sf(lake_centers, coords=c(&#39;nhd_long&#39;, &#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) subset_spatial &lt;- spatial_lakes %&gt;% slice(1:100) subset_baser &lt;- spatial_lakes[1:100,] ## nutr &lt;- lagos$epi_nutr clarity_only &lt;- nutr %&gt;% select(lagoslakeid, sampledate, chla, doc, secchi) %&gt;% mutate(sampledate = as.character(sampledate) %&gt;% ymd(.)) chla_secchi &lt;- clarity_only %&gt;% filter(!is.na(chla), !is.na(secchi)) chla_secchi_200 &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% filter(count &gt; 200) spatial_200 &lt;- inner_join(spatial_lakes,chla_secchi_200 %&gt;% distinct(lagoslakeid,.keep_all=T), by=&#39;lagoslakeid&#39;) mean_values_200 &lt;- chla_secchi_200 %&gt;% group_by(lagoslakeid) %&gt;% summarize(mean_chl = mean(chla,na.rm=T), mean_secchi=mean(secchi,na.rm=T)) %&gt;% filter(!is.na(mean_chl), !is.na(mean_secchi)) %&gt;% mutate(log10_mean_chl = log10(mean_chl)) mean_spatial &lt;- inner_join(spatial_lakes,mean_values_200, by=&#39;lagoslakeid&#39;) 4.2 Question 1 Show a map outline of Iowa and Illinois. states &lt;- us_states() il.ia.states &lt;- states %&gt;% filter(name %in% c(&quot;Iowa&quot;, &quot;Illinois&quot;)) %&gt;% st_transform(2163) mapview(il.ia.states) 4.3 Question 2 Subset LAGOS data to these sites, how many sites are in Illinois and Iowa combined? How does this compare to Minnesota? il.ia.lakes &lt;- spatial_lakes[il.ia.states,] minnesota &lt;- states %&gt;% filter(name == &#39;Minnesota&#39;) %&gt;% st_transform(2163) minnesota_lakes &lt;- spatial_lakes[minnesota,] nrow(minnesota_lakes) ## [1] 29038 nrow(il.ia.lakes) ## [1] 16466 Minnesota truly is the land of lakes, with almost double the number of lakes as Iowa and Illinois combined (16,466 vs. 29,038, respectivley). 4.4 Question 3 What is the distribution of lake size in Iowa vs. Minnesota? combined.lake.data &lt;- il.ia.states %&gt;% filter(name == &quot;Iowa&quot;) %&gt;% spatial_lakes[.,] %&gt;% bind_rows(minnesota_lakes) %&gt;% mutate(State_Name = ifelse(state_zoneid == &quot;State_13&quot;, &quot;Minnesota&quot;, &quot;Iowa&quot;)) ggplot(combined.lake.data) + geom_histogram(aes(x = lake_area_ha, y = ..ncount..), color = &quot;black&quot;,) + facet_grid(.~State_Name) + scale_y_continuous(name = &quot;# of Lakes&quot;, limits = c(0, 1.01), expand = c(0, 0)) + scale_x_log10(name = &quot;log(Lake area (ha))&quot;) + theme_classic2() + theme(panel.background = element_rect(fill = NULL, color = &quot;black&quot;), strip.background = element_blank(), axis.text = element_text(color = &quot;black&quot;)) The distribution of lake size is more equally spread in MN compared to IA. In both states, most lakes are ~ 1 ha, but in MN there are more large lakes than there are in IA. 4.5 Question 4 Make an interactive plot of lakes in Iowa and Illinois and color them by lake area in hectares. mapview(il.ia.lakes, zcol = &#39;lake_area_ha&#39;) 4.6 Question 5 What is the correlation between Secchi Disk Depth and Chlorophyll a for sites with at least 200 observations? ggplot(mean_values_200, aes(x = mean_secchi, y = log(mean_chl))) + geom_smooth(method = &quot;lm&quot;, se = F, color = &quot;grey50&quot;, lty = 2) + annotate(geom = &quot;text&quot;, x = 7, y = 3.5, label = paste0(&quot;r = &quot;, round(cor(mean_values_200$mean_secchi, mean_values_200$log10_mean_chl), 3))) + xlab(&quot;Average Secchi Disk Depth&quot;) + ylab(&quot;Log(Chlorophyll A)&quot;) + geom_point(size = 2) + theme_classic2() + theme(panel.border = element_rect(fill = NA), axis.text = element_text(color = &quot;black&quot;), legend.position = c(0.85,0.15)) 4.7 Question 6 What states have the most data? nutrient.data &lt;- lagos$epi_nutr counts.data &lt;- nutrient.data %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% inner_join(spatial_lakes, ., by=&#39;lagoslakeid&#39;) states &lt;- us_states() %&gt;% st_transform(2163) counts.data &lt;- st_join(counts.data, states) lake.counts &lt;- aggregate(count ~ state_name, data = counts.data, FUN = sum) lake.counts &lt;- arrange(lake.counts, desc(count)) lake.counts %&gt;% kbl(col.names = c(&quot;State&quot;, &quot;Number of Obs.&quot;)) %&gt;% kable_minimal() State Number of Obs. Minnesota 131355769 Wisconsin 34753812 Michigan 30359567 Maine 25348856 Vermont 17129034 Rhode Island 7649578 New York 7226976 Missouri 1648314 New Hampshire 703338 Ohio 578968 Arkansas 183184 Pennsylvania 182218 Connecticut 153866 Iowa 95294 Illinois 81379 Massachusetts 22919 South Dakota 7865 Indiana 6617 New Jersey 1808 Nebraska 1282 Maryland 4 4.8 Question 7 Is there a spatial pattern in Secchi disk depth for lakes with at least 200 observations? mapview(mean_spatial, zcol = &quot;mean_secchi&quot;) Yes, there is a general spatial pattern in the Secchi disk depth. Of the lakes with at least 200 observations, lakes in the major agricultural regions (i.e., the central United States) tend to have a more shallow average Secchi disk depth value. In contrast, lakes in the upper eastern portion of the country have deeper Secchi disk depth values, possibly due to a decrease in the amount of phytoplankton growth facilitated by fertilizer runoff and grounwater nutrient loading. "],["chapter-4---linear-regressions.html", "Chapter 5 Chapter 4 - Linear Regressions 5.1 Importing the data and cleaning it up. 5.2 Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend? 5.3 Question 2 5.4 Question 3 5.5 Question 4 5.6 Question 5", " Chapter 5 Chapter 4 - Linear Regressions 5.1 Importing the data and cleaning it up. prism &lt;- readMat(&quot;./Data/Chapter_4/prismiowa.mat&quot;) dimnames(prism$tmaxdaily.iowa) &lt;- list(prism$COUNTYFP, 1:366, prism$years) tmaxdf &lt;- as.data.frame.table(prism$tmaxdaily.iowa) colnames(tmaxdf) &lt;- c(&quot;countyfp&quot;,&quot;doy&quot;,&quot;year&quot;,&quot;tmax&quot;) tmaxdf &lt;- tibble(tmaxdf) tmaxdf$doy &lt;- as.numeric(tmaxdf$doy) tmaxdf$year &lt;- as.numeric(as.character(tmaxdf$year)) winnesummer &lt;- tmaxdf %&gt;% filter(countyfp==191 &amp; doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) winnewinter &lt;- tmaxdf %&gt;% filter(countyfp==191 &amp; (doy &lt;= 59 | doy &gt;= 335) &amp; !is.na(tmax)) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) nassqs_auth(key = &quot;11FCF4DC-1B74-3577-B8A5-5F09B27E2390&quot;) params &lt;- list(commodity_desc = &quot;CORN&quot;, util_practice_desc = &quot;GRAIN&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1981, state_alpha = &quot;IA&quot;) cornyieldsall &lt;- nassqs_yields(params) cornyieldsall$county_ansi &lt;- as.numeric(cornyieldsall$county_ansi) cornyieldsall$yield &lt;- as.numeric(cornyieldsall$Value) cornyields &lt;- select(cornyieldsall, county_ansi, county_name, yield, year) %&gt;% filter(!is.na(county_ansi) &amp; !is.na(yield)) cornyields &lt;- tibble(cornyields) 5.2 Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend? winneshiek &lt;- cornyields %&gt;% filter(county_name == &quot;WINNESHIEK&quot;) winneshiek.lm &lt;- lm(yield ~ year, data = winneshiek) summary(winneshiek.lm) ## ## Call: ## lm(formula = yield ~ year, data = winneshiek) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.163 -1.841 2.363 9.437 24.376 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4763.290 448.286 -10.63 4.46e-13 *** ## year 2.457 0.224 10.96 1.77e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 16.97 on 39 degrees of freedom ## Multiple R-squared: 0.7551, Adjusted R-squared: 0.7488 ## F-statistic: 120.2 on 1 and 39 DF, p-value: 1.767e-13 winneshiek$fitted.yield.lm &lt;- winneshiek.lm$fitted.values ggplot(winneshiek) + geom_point(aes(x = year, y = yield)) + geom_line(aes(x = year, y = fitted.yield.lm), lty = 2) + ylab(expression(&quot;Yield (bu&quot;~acre^-1*&quot;)&quot;)) + xlab(&quot;Year&quot;) + theme_minimal() There is a significant time trend (p-value &lt; 0.001). Year explains ~75% of the variability in the yield data. While there are some obvious outliers (e.g., 1993), maize yield tend to increase overtime by a rate of ~2.5 bushels per acre per year. 5.2.1 Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? winneshiek &lt;- winneshiek %&gt;% mutate(year_2 = year^2) winneshiek.qm &lt;- lm(yield ~ year + year_2, data = winneshiek) summary(winneshiek.qm) ## ## Call: ## lm(formula = yield ~ year + year_2, data = winneshiek) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.384 -3.115 1.388 9.743 25.324 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.583e+04 8.580e+04 0.301 0.765 ## year -2.812e+01 8.576e+01 -0.328 0.745 ## year_2 7.641e-03 2.143e-02 0.357 0.723 ## ## Residual standard error: 17.17 on 38 degrees of freedom ## Multiple R-squared: 0.7559, Adjusted R-squared: 0.7431 ## F-statistic: 58.84 on 2 and 38 DF, p-value: 2.311e-12 anova(winneshiek.qm) ## Analysis of Variance Table ## ## Response: yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## year 1 34638 34638 117.5462 3.445e-13 *** ## year_2 1 37 37 0.1271 0.7234 ## Residuals 38 11198 295 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 winneshiek$fitted.yield.qm &lt;- winneshiek.qm$fitted.values ggplot(winneshiek) + geom_point(aes(x = year, y = yield)) + geom_line(aes(x = year, y = fitted.yield.qm), lty = 2) + ylab(expression(&quot;Yield (bu&quot;~acre^-1*&quot;)&quot;)) + xlab(&quot;Year&quot;) + theme_minimal() In Winnesheiek county, there is no evidence of slowing yield growth for corn. The quadratic parameter is not significant, and does not add explanatory power to the model. If anything, there has been an insignificant but noticible increase in the rate of yield growth in the decade since 2010, implying that yield growth might be increasing. 5.3 Question 2 Time Series: Lets analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results. winneshiek.climate &lt;- cornyields %&gt;% filter(county_name == &quot;WINNESHIEK&quot;) %&gt;% right_join(., winnesummer, by = &quot;year&quot;) ### Linear model winneshiek.climate.lm &lt;- lm(yield ~ meantmax, data = winneshiek.climate) summary(winneshiek.climate.lm) ## ## Call: ## lm(formula = yield ~ meantmax, data = winneshiek.climate) ## ## Residuals: ## Min 1Q Median 3Q Max ## -71.96 -19.85 -3.19 24.64 61.72 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 275.876 118.335 2.331 0.0255 * ## meantmax -4.763 4.438 -1.073 0.2902 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 32.88 on 36 degrees of freedom ## Multiple R-squared: 0.03101, Adjusted R-squared: 0.004098 ## F-statistic: 1.152 on 1 and 36 DF, p-value: 0.2902 fitted.values.lm &lt;- winneshiek.climate.lm$fitted.values ### Multiple regression winneshiek.climate.mlm &lt;- lm(yield ~ meantmax + year, data = winneshiek.climate) summary(winneshiek.climate.mlm) ## ## Call: ## lm(formula = yield ~ meantmax + year, data = winneshiek.climate) ## ## Residuals: ## Min 1Q Median 3Q Max ## -53.071 -7.269 2.271 9.935 27.505 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4791.774 513.812 -9.326 5.10e-11 *** ## meantmax -3.201 2.308 -1.387 0.174 ## year 2.514 0.253 9.934 1.01e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.06 on 35 degrees of freedom ## Multiple R-squared: 0.7463, Adjusted R-squared: 0.7318 ## F-statistic: 51.48 on 2 and 35 DF, p-value: 3.761e-11 fitted.values.mlm &lt;- predict(winneshiek.climate.mlm, newdata = data.frame(meantmax = winneshiek.climate$meantmax, year = winneshiek.climate$year)) ### Quadratic multiple regression winneshiek.climate &lt;- winneshiek.climate %&gt;% mutate(tmax_2 = meantmax^2) winneshiek.climate.mqm &lt;- lm(yield ~ meantmax + tmax_2, data = winneshiek.climate) summary(winneshiek.climate.mqm) ## ## Call: ## lm(formula = yield ~ meantmax + tmax_2, data = winneshiek.climate) ## ## Residuals: ## Min 1Q Median 3Q Max ## -56.587 -22.262 -0.982 22.409 52.798 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4223.604 1446.639 -2.920 0.00609 ** ## meantmax 328.918 107.068 3.072 0.00410 ** ## tmax_2 -6.173 1.979 -3.119 0.00362 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.5 on 35 degrees of freedom ## Multiple R-squared: 0.2417, Adjusted R-squared: 0.1984 ## F-statistic: 5.579 on 2 and 35 DF, p-value: 0.007887 fitted.values.mqm &lt;- winneshiek.climate.mqm$fitted.values ### model.comparison &lt;- tibble(Model = c(rep(&quot;Yield ~ Max Temperature&quot;, length = 38), rep(&quot;Yield ~ Year + Max Temperature&quot;, length = 38), rep(&quot;Yield ~ Max Temperature + Max Temperature^2&quot;, length = 38)), T_Max = rep(winneshiek.climate$meantmax, 3), Fitted = c(fitted.values.lm, fitted.values.mlm, fitted.values.mqm)) ### ggplot(data = winneshiek.climate, aes(x = meantmax, y = yield)) + geom_point() + geom_line(data = model.comparison, aes(x = T_Max, y = Fitted, color = Model)) + ylab(expression(&quot;Yield (bu&quot;~acre^-1*&quot;)&quot;)) + xlab(&quot;Max Temperature (C)&quot;) + theme_minimal() + theme(legend.position = c(0.8,0.9)) There is a significant negative, nonlinear relationship between maximum annual temperature and average yield in Winnesheik county. This trend is best captured by the quadratic mode, which shows that yields rise to a maxima at ~27 degrees C, after which they begin to fall. Further analysis should investigate the interaction between the month during which max temperature was observed and max temerature, as corn growth stage response to temperature may confound results. Adding year to the model helps to explain some of the variance, but results are significant in either case. Adding yead as a random effect in a mixed model in future analyses may provide even more robust results. 5.4 Question 3 Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results. climate.yield.data &lt;- tmaxdf %&gt;% filter(doy %in% seq(152, 243)) %&gt;% group_by(countyfp, year) %&gt;% summarise(Max_Temp = mean(tmax, na.rm = T)) %&gt;% mutate(Max_Temp2 = Max_Temp^2) %&gt;% mutate(countyfp = as.numeric(as.character((countyfp)))) %&gt;% left_join(x = ., y = cornyields, by = c(&quot;year&quot;, &quot;countyfp&quot; = &quot;county_ansi&quot;)) %&gt;% filter(is.na(yield) == F) ## `summarise()` has grouped output by &#39;countyfp&#39;. You can override using the `.groups` argument. state.level.lm &lt;- lm(yield ~ Max_Temp + Max_Temp2, data = climate.yield.data) climate.yield.data$Fitted &lt;- state.level.lm$fitted.values summary(state.level.lm) ## ## Call: ## lm(formula = yield ~ Max_Temp + Max_Temp2, data = climate.yield.data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -113.151 -21.982 -2.794 24.860 82.006 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2098.6219 139.4315 -15.05 &lt;2e-16 *** ## Max_Temp 168.9590 9.9402 17.00 &lt;2e-16 *** ## Max_Temp2 -3.1665 0.1769 -17.90 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 31.55 on 3745 degrees of freedom ## Multiple R-squared: 0.1947, Adjusted R-squared: 0.1943 ## F-statistic: 452.8 on 2 and 3745 DF, p-value: &lt; 2.2e-16 anova(state.level.lm) ## Analysis of Variance Table ## ## Response: yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Max_Temp 1 582759 582759 585.34 &lt; 2.2e-16 *** ## Max_Temp2 1 318854 318854 320.27 &lt; 2.2e-16 *** ## Residuals 3745 3728463 996 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ggplot(data = climate.yield.data, aes(x = Max_Temp, y = yield)) + geom_point() + geom_line(aes(x = Max_Temp, y = Fitted), color = &quot;red&quot;, lty = 2, size = 1.5) + ylab(expression(&quot;Yield (bu&quot;~acre^-1*&quot;)&quot;)) + xlab(&quot;Maximum Temperature (C)&quot;) + theme_minimal() Yes, there is a significant relationship between maximum temperature and corn yields analyzed across all IA counties. When evaluated using a linear predictor, yields decline by ~ 9 bushels per acre per 1 degree increase in max temperature. However, yields decline more rapidly at higher temperatures, and as such a quadratic model is more appropriate for analyzing these data. The variability in yield (likely a function of variability in soil properties, management, and precipitation) lead to the model explaining only 19% of the variability, however the model shows significance for both the maximum temperature term, as well as the quadratic term. 5.5 Question 4 Panel: One way to leverage multiple time series is to group all data into what is called a panel regression. Convert the county ID code (countyfp or county_ansi) into factor using as.factor, then include this variable in a regression using all counties yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model. climate.yield.data &lt;- climate.yield.data %&gt;% mutate(county_name = as.factor(county_name)) panel.lm &lt;- lm(yield ~ Max_Temp + Max_Temp2 + county_name, data = climate.yield.data) summary(panel.lm) ## ## Call: ## lm(formula = yield ~ Max_Temp + Max_Temp2 + county_name, data = climate.yield.data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -95.088 -21.438 -3.026 23.570 77.941 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2102.2327 139.2946 -15.092 &lt; 2e-16 *** ## Max_Temp 167.9699 9.8950 16.975 &lt; 2e-16 *** ## Max_Temp2 -3.1324 0.1758 -17.820 &lt; 2e-16 *** ## county_nameADAMS -4.5577 7.0388 -0.648 0.517347 ## county_nameALLAMAKEE 1.9797 7.0743 0.280 0.779612 ## county_nameAPPANOOSE -19.1369 7.0864 -2.701 0.006955 ** ## county_nameAUDUBON 4.3024 7.0416 0.611 0.541240 ## county_nameBENTON 6.2752 7.0459 0.891 0.373195 ## county_nameBLACK HAWK 6.2028 7.0520 0.880 0.379147 ## county_nameBOONE 14.3129 7.0414 2.033 0.042157 * ## county_nameBREMER 10.2595 7.0568 1.454 0.146076 ## county_nameBUCHANAN 6.6549 7.0596 0.943 0.345912 ## county_nameBUENA VISTA 7.5427 7.0503 1.070 0.284760 ## county_nameBUTLER 8.0045 7.0493 1.135 0.256242 ## county_nameCALHOUN 9.3627 7.0468 1.329 0.184048 ## county_nameCARROLL 8.8039 7.0426 1.250 0.211348 ## county_nameCASS 6.0858 7.0389 0.865 0.387315 ## county_nameCEDAR 14.9921 7.0443 2.128 0.033381 * ## county_nameCERRO GORDO 3.7400 7.0668 0.529 0.596677 ## county_nameCHEROKEE 12.8689 7.0455 1.827 0.067848 . ## county_nameCHICKASAW 1.3837 7.0714 0.196 0.844876 ## county_nameCLARKE -24.9874 7.0863 -3.526 0.000427 *** ## county_nameCLAY 5.5213 7.0521 0.783 0.433716 ## county_nameCLAYTON 7.9986 7.0648 1.132 0.257632 ## county_nameCLINTON 9.7142 7.0455 1.379 0.168043 ## county_nameCRAWFORD 5.5829 7.0436 0.793 0.428054 ## county_nameDALLAS 10.5962 7.0391 1.505 0.132323 ## county_nameDAVIS -14.6474 7.0887 -2.066 0.038872 * ## county_nameDECATUR -16.7641 7.0865 -2.366 0.018051 * ## county_nameDELAWARE 8.6421 7.0667 1.223 0.221435 ## county_nameDES MOINES 10.8382 7.0391 1.540 0.123719 ## county_nameDICKINSON 2.0837 7.0635 0.295 0.768011 ## county_nameDUBUQUE 9.1371 7.0690 1.293 0.196245 ## county_nameEMMET 6.4115 7.0706 0.907 0.364579 ## county_nameFAYETTE 6.5576 7.0722 0.927 0.353862 ## county_nameFLOYD 3.8270 7.0595 0.542 0.587775 ## county_nameFRANKLIN 10.2572 7.0536 1.454 0.145983 ## county_nameFREMONT 15.9700 7.0526 2.264 0.023608 * ## county_nameGREENE 14.2209 7.0396 2.020 0.043445 * ## county_nameGRUNDY 10.3933 7.0506 1.474 0.140543 ## county_nameGUTHRIE 3.0582 7.0392 0.434 0.663988 ## county_nameHAMILTON 12.1993 7.0442 1.732 0.083392 . ## county_nameHANCOCK 7.8892 7.0692 1.116 0.264496 ## county_nameHARDIN 13.0042 7.0463 1.846 0.065040 . ## county_nameHARRISON 7.0324 7.0390 0.999 0.317828 ## county_nameHENRY 5.8050 7.0396 0.825 0.409641 ## county_nameHOWARD 0.9492 7.1084 0.134 0.893781 ## county_nameHUMBOLDT 8.8848 7.0596 1.259 0.208279 ## county_nameIDA 10.8610 7.0456 1.542 0.123276 ## county_nameIOWA 6.7101 7.0403 0.953 0.340600 ## county_nameJACKSON -2.2777 7.0533 -0.323 0.746768 ## county_nameJASPER 13.8935 7.0402 1.973 0.048519 * ## county_nameJEFFERSON 2.1063 7.0445 0.299 0.764958 ## county_nameJOHNSON 3.8916 7.0404 0.553 0.580470 ## county_nameJONES 6.8541 7.0503 0.972 0.331025 ## county_nameKEOKUK 2.4290 7.0390 0.345 0.730052 ## county_nameKOSSUTH 11.2195 7.0616 1.589 0.112188 ## county_nameLEE 3.2019 7.0439 0.455 0.649452 ## county_nameLINN 5.5167 7.0475 0.783 0.433799 ## county_nameLOUISA 8.0182 7.0400 1.139 0.254798 ## county_nameLUCAS -23.7701 7.1360 -3.331 0.000874 *** ## county_nameLYON 8.4973 7.0446 1.206 0.227815 ## county_nameMADISON -2.7616 7.0390 -0.392 0.694843 ## county_nameMAHASKA 8.2674 7.0389 1.175 0.240260 ## county_nameMARION 2.0919 7.0389 0.297 0.766339 ## county_nameMARSHALL 13.1465 7.0469 1.866 0.062181 . ## county_nameMILLS 9.7388 7.1425 1.364 0.172806 ## county_nameMITCHELL 6.9486 7.0897 0.980 0.327099 ## county_nameMONONA 1.2117 7.0395 0.172 0.863346 ## county_nameMONROE -16.6425 7.0863 -2.349 0.018900 * ## county_nameMONTGOMERY 6.6056 7.0404 0.938 0.348183 ## county_nameMUSCATINE 8.2715 7.0389 1.175 0.240027 ## county_nameO BRIEN 13.1679 7.0506 1.868 0.061894 . ## county_nameOSCEOLA 7.9469 7.0654 1.125 0.260765 ## county_namePAGE 0.4131 7.0406 0.059 0.953217 ## county_namePALO ALTO 6.1297 7.0527 0.869 0.384835 ## county_namePLYMOUTH 6.7353 7.0404 0.957 0.338798 ## county_namePOCAHONTAS 10.3788 7.0476 1.473 0.140925 ## county_namePOLK 14.0238 7.0389 1.992 0.046410 * ## county_namePOTTAWATTAMIE 10.4059 7.0864 1.468 0.142075 ## county_namePOWESHIEK 10.1606 7.0397 1.443 0.149014 ## county_nameRINGGOLD -20.5978 7.0389 -2.926 0.003451 ** ## county_nameSAC 8.4110 7.0478 1.193 0.232778 ## county_nameSCOTT 15.5360 7.0426 2.206 0.027446 * ## county_nameSHELBY 6.9179 7.0417 0.982 0.325957 ## county_nameSIOUX 14.7911 7.0423 2.100 0.035770 * ## county_nameSTORY 10.2395 7.0458 1.453 0.146233 ## county_nameTAMA 8.7662 7.0459 1.244 0.213519 ## county_nameTAYLOR -14.5056 7.0868 -2.047 0.040744 * ## county_nameUNION -12.5580 7.0863 -1.772 0.076452 . ## county_nameVAN BUREN -2.8371 7.0524 -0.402 0.687493 ## county_nameWAPELLO -3.5740 7.0874 -0.504 0.614105 ## county_nameWARREN -2.0199 7.0389 -0.287 0.774154 ## county_nameWASHINGTON 10.8835 7.0394 1.546 0.122169 ## county_nameWAYNE -22.9077 7.0863 -3.233 0.001237 ** ## county_nameWEBSTER 13.1211 7.0472 1.862 0.062700 . ## county_nameWINNEBAGO 7.5593 7.0757 1.068 0.285441 ## county_nameWINNESHIEK 4.0826 7.0867 0.576 0.564584 ## county_nameWOODBURY 2.3508 7.0395 0.334 0.738436 ## county_nameWORTH 5.9103 7.0954 0.833 0.404908 ## county_nameWRIGHT 10.4404 7.0518 1.481 0.138817 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 30.68 on 3647 degrees of freedom ## Multiple R-squared: 0.2585, Adjusted R-squared: 0.2382 ## F-statistic: 12.71 on 100 and 3647 DF, p-value: &lt; 2.2e-16 climate.yield.data$fitted &lt;- panel.lm$fitted.values ggplot(data = climate.yield.data, aes(y = fitted, x = yield)) + geom_point() + xlab(expression(&quot;Measured Yield (bu&quot;~acre^-1*&quot;)&quot;)) + ylab(expression(&quot;Fitted Yield (bu&quot;~acre^-1*&quot;)&quot;)) + theme_minimal() In the panel regression, temperature coefficents are highly significant (p-value &lt; 0.001). Including county as a factor increase the amount of variability explained by the model, and gives insight into counties where this trend is most significant. Interestingly, modeled yields tend to find a maximum at ~ 165 bu per acre, limiting the ability of the model to capture variability in high yielding counties. 5.6 Question 5 Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years. soybean.params &lt;- list(commodity_desc = &quot;SOYBEANS&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1965, state_alpha = &quot;IA&quot;) soybean.yields &lt;- nassqs_yields(soybean.params) soybean.yields &lt;- soybean.yields %&gt;% mutate(Yield = as.numeric(Value)) %&gt;% mutate(county_ansi = as.numeric(county_ansi)) %&gt;% select(county_ansi, county_name, Yield, year) %&gt;% filter(!is.na(county_ansi) &amp; !is.na(Yield)) %&gt;% mutate(county_name = as.factor(county_name)) %&gt;% tibble(.) %&gt;% mutate(yearsq = year^2) desmoines.lm.a &lt;- lm(Yield ~ year + yearsq, data = soybean.yields[soybean.yields$county_name == &quot;DES MOINES&quot;,]) desmoines.lm.b &lt;- lm(Yield ~ year, data = soybean.yields[soybean.yields$county_name == &quot;DES MOINES&quot;,]) summary(desmoines.lm.a) ## ## Call: ## lm(formula = Yield ~ year + yearsq, data = soybean.yields[soybean.yields$county_name == ## &quot;DES MOINES&quot;, ]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.301 -2.703 0.222 3.153 7.794 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.025e+04 9.651e+03 2.098 0.0406 * ## year -2.073e+01 9.688e+00 -2.140 0.0370 * ## yearsq 5.315e-03 2.431e-03 2.186 0.0332 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.249 on 53 degrees of freedom ## Multiple R-squared: 0.7586, Adjusted R-squared: 0.7494 ## F-statistic: 83.26 on 2 and 53 DF, p-value: &lt; 2.2e-16 summary(desmoines.lm.b) ## ## Call: ## lm(formula = Yield ~ year, data = soybean.yields[soybean.yields$county_name == ## &quot;DES MOINES&quot;, ]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.1035 -3.4246 0.7288 3.2426 8.7950 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -846.56377 72.40675 -11.69 &lt;2e-16 *** ## year 0.44676 0.03634 12.29 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.395 on 54 degrees of freedom ## Multiple R-squared: 0.7368, Adjusted R-squared: 0.7319 ## F-statistic: 151.2 on 1 and 54 DF, p-value: &lt; 2.2e-16 ggplot(data = soybean.yields[soybean.yields$county_name == &quot;DES MOINES&quot;,], aes(x = year, y = Yield)) + geom_point() + ylab(expression(&quot;Yield (bu&quot;~acre^-1*&quot;)&quot;)) + xlab(&quot;Year&quot;) + theme_minimal() I thought it could be interesting to see if increases in technology accelerated the yield growth of soybeans in Des Moines county if we looked further back in time. The models show that this is not the case; similar to the first question, yield growth is linear for soybeans in Des Moines county. A linear model performs better than the quadratic. Part of this could be the prevalence of continuous corn in the Des Moines lobe region, but its hard to tell without further data. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
